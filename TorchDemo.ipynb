{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('3.6.5 |Anaconda, Inc.| (default, Apr 29 2018, 16:14:56) \\n[GCC 7.2.0]',\n",
       " '/home/jared/galvanize/Projects/prouster')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.version, os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# categories: 18 ['French', 'Chinese', 'Dutch', 'Czech', 'Portuguese', 'Russian', 'Italian', 'Spanish', 'Irish', 'Vietnamese', 'Greek', 'Polish', 'Japanese', 'English', 'Scottish', 'Arabic', 'German', 'Korean']\n",
      "O'Neal\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'-\"\n",
    "n_letters = len(all_letters) + 1 # Plus EOS marker\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "# Build the category_lines dictionary, a list of lines per category\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "for filename in findFiles('data/torch-demo/data/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "if n_categories == 0:\n",
    "    raise RuntimeError('Data not found. Make sure that you downloaded data '\n",
    "        'from https://download.pytorch.org/tutorial/data.zip and extract it to '\n",
    "        'the current directory.')\n",
    "\n",
    "print('# categories:', n_categories, all_categories)\n",
    "print(unicodeToAscii(\"O'Néàl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(n_categories + input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(n_categories + input_size + hidden_size, output_size)\n",
    "        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, category, input, hidden):\n",
    "        input_combined = torch.cat((category, input, hidden), 1)\n",
    "        hidden = self.i2h(input_combined)\n",
    "        output = self.i2o(input_combined)\n",
    "        output_combined = torch.cat((hidden, output), 1)\n",
    "        output = self.o2o(output_combined)\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Random item from a list\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "# Get a random category and random line from that category\n",
    "def randomTrainingPair():\n",
    "    category = randomChoice(all_categories)\n",
    "    line = randomChoice(category_lines[category])\n",
    "    return category, line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categoryTensor(category):\n",
    "    li = all_categories.index(category)\n",
    "    tensor = torch.zeros(1, n_categories)\n",
    "    tensor[0][li] = 1\n",
    "    return tensor\n",
    "\n",
    "# One-hot matrix of first to last letters (not including EOS) for input\n",
    "def inputTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li in range(len(line)):\n",
    "        letter = line[li]\n",
    "        tensor[li][0][all_letters.find(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# LongTensor of second letter to end (EOS) for target\n",
    "def targetTensor(line):\n",
    "    letter_indexes = [all_letters.find(line[li]) for li in range(1, len(line))]\n",
    "    letter_indexes.append(n_letters - 1) # EOS\n",
    "    return torch.LongTensor(letter_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomTrainingExample():\n",
    "    category, line = randomTrainingPair()\n",
    "    category_tensor = categoryTensor(category)\n",
    "    input_line_tensor = inputTensor(line)\n",
    "    target_line_tensor = targetTensor(line)\n",
    "    return category_tensor, input_line_tensor, target_line_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "\n",
    "learning_rate = 0.0005\n",
    "\n",
    "def train(category_tensor, input_line_tensor, target_line_tensor):\n",
    "    target_line_tensor.unsqueeze_(-1)\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for i in range(input_line_tensor.size(0)):\n",
    "        output, hidden = rnn(category_tensor, input_line_tensor[i], hidden)\n",
    "        l = criterion(output, target_line_tensor[i])\n",
    "        loss += l\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(-learning_rate, p.grad.data)\n",
    "\n",
    "    return output, loss.item() / input_line_tensor.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 3s (500 0%) 3.8375\n",
      "0m 5s (1000 1%) 3.4376\n",
      "0m 8s (1500 1%) 3.8089\n",
      "0m 11s (2000 2%) 3.2492\n",
      "0m 14s (2500 2%) 2.9138\n",
      "0m 17s (3000 3%) 3.5077\n",
      "0m 20s (3500 3%) 3.0670\n",
      "0m 23s (4000 4%) 2.7751\n",
      "0m 26s (4500 4%) 3.0838\n",
      "0m 30s (5000 5%) 2.4271\n",
      "0m 33s (5500 5%) 3.3270\n",
      "0m 36s (6000 6%) 2.8637\n",
      "0m 39s (6500 6%) 2.5478\n",
      "0m 41s (7000 7%) 3.0155\n",
      "0m 44s (7500 7%) 2.3647\n",
      "0m 47s (8000 8%) 2.9685\n",
      "0m 50s (8500 8%) 3.7140\n",
      "0m 53s (9000 9%) 2.5076\n",
      "0m 56s (9500 9%) 2.0441\n",
      "1m 0s (10000 10%) 2.7480\n",
      "1m 2s (10500 10%) 3.1334\n",
      "1m 5s (11000 11%) 2.5099\n",
      "1m 8s (11500 11%) 2.6107\n",
      "1m 10s (12000 12%) 2.8107\n",
      "1m 13s (12500 12%) 2.8401\n",
      "1m 16s (13000 13%) 2.7853\n",
      "1m 19s (13500 13%) 2.8921\n",
      "1m 21s (14000 14%) 2.3880\n",
      "1m 24s (14500 14%) 2.5759\n",
      "1m 26s (15000 15%) 2.8394\n",
      "1m 29s (15500 15%) 2.0841\n",
      "1m 32s (16000 16%) 2.7144\n",
      "1m 35s (16500 16%) 3.2359\n",
      "1m 38s (17000 17%) 2.2015\n",
      "1m 41s (17500 17%) 2.6492\n",
      "1m 44s (18000 18%) 2.1794\n",
      "1m 46s (18500 18%) 3.0697\n",
      "1m 49s (19000 19%) 2.2921\n",
      "1m 52s (19500 19%) 2.9639\n",
      "1m 55s (20000 20%) 2.4994\n",
      "1m 57s (20500 20%) 2.6940\n",
      "2m 0s (21000 21%) 2.9781\n",
      "2m 3s (21500 21%) 2.0137\n",
      "2m 5s (22000 22%) 2.8475\n",
      "2m 8s (22500 22%) 2.7896\n",
      "2m 11s (23000 23%) 2.5299\n",
      "2m 13s (23500 23%) 1.9729\n",
      "2m 16s (24000 24%) 3.1683\n",
      "2m 19s (24500 24%) 2.0994\n",
      "2m 21s (25000 25%) 3.6615\n",
      "2m 24s (25500 25%) 2.2389\n",
      "2m 27s (26000 26%) 3.2688\n",
      "2m 30s (26500 26%) 2.8254\n",
      "2m 34s (27000 27%) 2.8009\n",
      "2m 37s (27500 27%) 2.9078\n",
      "2m 40s (28000 28%) 2.8544\n",
      "2m 43s (28500 28%) 3.0832\n",
      "2m 46s (29000 28%) 2.0154\n",
      "2m 49s (29500 29%) 2.6972\n",
      "2m 52s (30000 30%) 2.1011\n",
      "2m 54s (30500 30%) 2.3926\n",
      "2m 57s (31000 31%) 3.2731\n",
      "3m 0s (31500 31%) 4.0350\n",
      "3m 3s (32000 32%) 2.5255\n",
      "3m 6s (32500 32%) 2.2686\n",
      "3m 9s (33000 33%) 2.5404\n",
      "3m 12s (33500 33%) 2.5757\n",
      "3m 14s (34000 34%) 1.7939\n",
      "3m 17s (34500 34%) 2.2818\n",
      "3m 19s (35000 35%) 1.8315\n",
      "3m 22s (35500 35%) 3.0089\n",
      "3m 25s (36000 36%) 2.0881\n",
      "3m 27s (36500 36%) 2.3300\n",
      "3m 30s (37000 37%) 3.0193\n",
      "3m 33s (37500 37%) 1.8165\n",
      "3m 35s (38000 38%) 2.3234\n",
      "3m 38s (38500 38%) 2.4466\n",
      "3m 41s (39000 39%) 3.0029\n",
      "3m 44s (39500 39%) 1.9190\n",
      "3m 47s (40000 40%) 2.1694\n",
      "3m 50s (40500 40%) 1.9697\n",
      "3m 53s (41000 41%) 2.0694\n",
      "3m 56s (41500 41%) 2.0542\n",
      "3m 58s (42000 42%) 2.6047\n",
      "4m 1s (42500 42%) 2.6309\n",
      "4m 4s (43000 43%) 2.3730\n",
      "4m 7s (43500 43%) 2.9957\n",
      "4m 10s (44000 44%) 2.6258\n",
      "4m 13s (44500 44%) 2.6616\n",
      "4m 16s (45000 45%) 2.3936\n",
      "4m 18s (45500 45%) 2.6356\n",
      "4m 21s (46000 46%) 2.9202\n",
      "4m 25s (46500 46%) 2.7107\n",
      "4m 28s (47000 47%) 2.2230\n",
      "4m 31s (47500 47%) 2.0837\n",
      "4m 33s (48000 48%) 2.8644\n",
      "4m 36s (48500 48%) 2.6896\n",
      "4m 39s (49000 49%) 2.4004\n",
      "4m 42s (49500 49%) 1.9035\n",
      "4m 44s (50000 50%) 2.1873\n",
      "4m 47s (50500 50%) 2.5999\n",
      "4m 49s (51000 51%) 1.9745\n",
      "4m 52s (51500 51%) 2.1668\n",
      "4m 55s (52000 52%) 2.8752\n",
      "4m 58s (52500 52%) 2.8887\n",
      "5m 0s (53000 53%) 1.6861\n",
      "5m 3s (53500 53%) 2.1273\n",
      "5m 6s (54000 54%) 2.6280\n",
      "5m 9s (54500 54%) 1.9153\n",
      "5m 12s (55000 55%) 1.9784\n",
      "5m 14s (55500 55%) 2.4277\n",
      "5m 17s (56000 56%) 1.9933\n",
      "5m 20s (56500 56%) 1.3135\n",
      "5m 22s (57000 56%) 2.9451\n",
      "5m 24s (57500 57%) 2.6600\n",
      "5m 27s (58000 57%) 2.5711\n",
      "5m 29s (58500 58%) 2.5707\n",
      "5m 32s (59000 59%) 2.1973\n",
      "5m 35s (59500 59%) 1.7629\n",
      "5m 38s (60000 60%) 2.4743\n",
      "5m 40s (60500 60%) 1.9087\n",
      "5m 42s (61000 61%) 2.1243\n",
      "5m 45s (61500 61%) 1.8904\n",
      "5m 48s (62000 62%) 3.7744\n",
      "5m 50s (62500 62%) 3.1711\n",
      "5m 53s (63000 63%) 2.6374\n",
      "5m 56s (63500 63%) 2.0070\n",
      "5m 59s (64000 64%) 2.9333\n",
      "6m 2s (64500 64%) 2.0307\n",
      "6m 5s (65000 65%) 2.5462\n",
      "6m 7s (65500 65%) 3.6123\n",
      "6m 10s (66000 66%) 1.8383\n",
      "6m 13s (66500 66%) 2.0083\n",
      "6m 16s (67000 67%) 2.4689\n",
      "6m 19s (67500 67%) 2.5521\n",
      "6m 21s (68000 68%) 1.6145\n",
      "6m 24s (68500 68%) 1.2128\n",
      "6m 27s (69000 69%) 3.2150\n",
      "6m 31s (69500 69%) 2.7133\n",
      "6m 34s (70000 70%) 0.9515\n",
      "6m 37s (70500 70%) 2.5916\n",
      "6m 41s (71000 71%) 2.1507\n",
      "6m 44s (71500 71%) 2.5257\n",
      "6m 47s (72000 72%) 1.6631\n",
      "6m 49s (72500 72%) 2.5714\n",
      "6m 53s (73000 73%) 2.3644\n",
      "6m 56s (73500 73%) 2.4638\n",
      "6m 58s (74000 74%) 1.6797\n",
      "7m 1s (74500 74%) 3.5606\n",
      "7m 4s (75000 75%) 2.4517\n",
      "7m 7s (75500 75%) 3.4233\n",
      "7m 9s (76000 76%) 2.3066\n",
      "7m 12s (76500 76%) 3.5485\n",
      "7m 14s (77000 77%) 1.9174\n",
      "7m 17s (77500 77%) 1.8974\n",
      "7m 20s (78000 78%) 2.6135\n",
      "7m 22s (78500 78%) 3.0092\n",
      "7m 25s (79000 79%) 2.8744\n",
      "7m 28s (79500 79%) 3.2425\n",
      "7m 31s (80000 80%) 2.9229\n",
      "7m 33s (80500 80%) 2.3204\n",
      "7m 36s (81000 81%) 2.4605\n",
      "7m 39s (81500 81%) 2.1239\n",
      "7m 41s (82000 82%) 2.0187\n",
      "7m 44s (82500 82%) 2.2275\n",
      "7m 46s (83000 83%) 3.0719\n",
      "7m 49s (83500 83%) 2.5138\n",
      "7m 52s (84000 84%) 1.3815\n",
      "7m 55s (84500 84%) 2.4671\n",
      "7m 58s (85000 85%) 1.7828\n",
      "8m 1s (85500 85%) 1.9463\n",
      "8m 4s (86000 86%) 1.2901\n",
      "8m 6s (86500 86%) 2.6400\n",
      "8m 9s (87000 87%) 1.9526\n",
      "8m 12s (87500 87%) 2.8869\n",
      "8m 15s (88000 88%) 1.9177\n",
      "8m 18s (88500 88%) 1.9242\n",
      "8m 21s (89000 89%) 1.9709\n",
      "8m 23s (89500 89%) 3.5119\n",
      "8m 27s (90000 90%) 2.3057\n",
      "8m 31s (90500 90%) 2.0285\n",
      "8m 34s (91000 91%) 2.5303\n",
      "8m 37s (91500 91%) 1.9639\n",
      "8m 40s (92000 92%) 2.4293\n",
      "8m 43s (92500 92%) 1.7881\n",
      "8m 46s (93000 93%) 1.5132\n",
      "8m 49s (93500 93%) 2.4000\n",
      "8m 52s (94000 94%) 2.5417\n",
      "8m 55s (94500 94%) 3.0498\n",
      "8m 58s (95000 95%) 2.2129\n",
      "9m 1s (95500 95%) 1.6279\n",
      "9m 4s (96000 96%) 2.8475\n",
      "9m 7s (96500 96%) 2.2934\n",
      "9m 10s (97000 97%) 1.5117\n",
      "9m 14s (97500 97%) 2.4376\n",
      "9m 17s (98000 98%) 2.6628\n",
      "9m 20s (98500 98%) 2.2419\n",
      "9m 23s (99000 99%) 1.7224\n",
      "9m 26s (99500 99%) 1.6530\n",
      "9m 30s (100000 100%) 1.6056\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN(n_letters, 128, n_letters)\n",
    "\n",
    "n_iters = 100000\n",
    "print_every = 500\n",
    "plot_every = n_iters\n",
    "all_losses = []\n",
    "total_loss = 0 # Reset every plot_every iters\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    output, loss = train(*randomTrainingExample())\n",
    "    total_loss += loss\n",
    "\n",
    "    if iter % print_every == 0:\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(start), iter, iter / n_iters * 100, loss))\n",
    "\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(total_loss / plot_every)\n",
    "        total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 50\n",
    "\n",
    "# Sample from a category and starting letter\n",
    "def sample(category, start_letter='A'):\n",
    "    with torch.no_grad():  # no need to track history in sampling\n",
    "        category_tensor = categoryTensor(category)\n",
    "        input = inputTensor(start_letter)\n",
    "        hidden = rnn.initHidden()\n",
    "\n",
    "        output_name = start_letter\n",
    "\n",
    "        for i in range(max_length):\n",
    "            output, hidden = rnn(category_tensor, input[0], hidden)\n",
    "            topv, topi = output.topk(random.randint(1,2))\n",
    "            topi = topi[0][0]\n",
    "            if topi == n_letters - 1:\n",
    "                break\n",
    "            else:\n",
    "                letter = all_letters[topi]\n",
    "                output_name += letter\n",
    "            input = inputTensor(letter)\n",
    "\n",
    "        return output_name\n",
    "\n",
    "# Get multiple samples from one category and multiple starting letters\n",
    "def samples(category, start_letters='ABC'):\n",
    "    for start_letter in start_letters:\n",
    "        print(sample(category, start_letter))\n",
    "\n",
    "samples('Russian', 'RUSE')\n",
    "\n",
    "samples('German', 'GERM')\n",
    "\n",
    "samples('Spanish', 'SPAN')\n",
    "\n",
    "samples('Chinese', 'CHIN')\n",
    "\n",
    "samples('Irish', 'IRLD')\n",
    "\n",
    "samples('Scottish', 'SCOT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rakov\n",
      "Uanon\n",
      "Shavan\n",
      "Eakan\n",
      "Garter\n",
      "Eerter\n",
      "Roun\n",
      "Merter\n",
      "Sanala\n",
      "Parer\n",
      "Alara\n",
      "Nara\n",
      "Cha\n",
      "Houn\n",
      "Iun\n",
      "Nan\n",
      "Iana\n",
      "Rongan\n",
      "Langan\n",
      "Dangara\n",
      "Santer\n",
      "Chang\n",
      "Oringel\n",
      "Trang\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
